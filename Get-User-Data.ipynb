{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80254d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import html\n",
    "import json\n",
    "\n",
    "import jsonlines\n",
    "\n",
    "import wand.image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2cd398",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81408e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\ayush\\\\OneDrive\\\\Desktop\\\\DataScience\\\\DataMining\\\\results\\\\final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa98b2f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>Clothing waste:\\nFast fashion advertising \"has...</td>\n",
       "      <td>1458187345522475011</td>\n",
       "      <td>2354958390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>'Fast fashion advertising \"has helped to convi...</td>\n",
       "      <td>1458049744488521737</td>\n",
       "      <td>53014733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>RT @RossiSongo: The fashion industry died for ...</td>\n",
       "      <td>1457882681530675206</td>\n",
       "      <td>313580985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>My anxiety acts up so damn bad!! And This damn...</td>\n",
       "      <td>1457813904680177665</td>\n",
       "      <td>1100867100074221568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>RT @RossiSongo: The fashion industry died for ...</td>\n",
       "      <td>1457767569381683200</td>\n",
       "      <td>728071920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang                                               text  \\\n",
       "0   en  Clothing waste:\\nFast fashion advertising \"has...   \n",
       "1   en  'Fast fashion advertising \"has helped to convi...   \n",
       "2   en  RT @RossiSongo: The fashion industry died for ...   \n",
       "3   en  My anxiety acts up so damn bad!! And This damn...   \n",
       "4   en  RT @RossiSongo: The fashion industry died for ...   \n",
       "\n",
       "                    id            author_id  \n",
       "0  1458187345522475011           2354958390  \n",
       "1  1458049744488521737             53014733  \n",
       "2  1457882681530675206            313580985  \n",
       "3  1457813904680177665  1100867100074221568  \n",
       "4  1457767569381683200            728071920  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "data.drop(data.index[(data[\"lang\"] != \"en\")],axis=0,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b359e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93010, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d983cae1",
   "metadata": {},
   "source": [
    "### Function to make GET call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f862c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUserData(ids):\n",
    "    headers = {'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAHpnVQEAAAAADoRcjCvSzB%2F0V0rJZDhxZJIhgbw%3DulfLRCCJEzxcT7kUTrRTGBxjNQqwFuBlRicJSfNrJDMIradvIb'}\n",
    "    url = \"https://api.twitter.com/2/users\"\n",
    "    params = {\n",
    "        'ids':ids,\n",
    "        'user.fields':'created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,url,username,verified,withheld',\n",
    "        'tweet.fields':'attachments,author_id,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang'\n",
    "    }\n",
    "    \n",
    "    r = requests.get(url=url, params=params, headers=headers)\n",
    "    \n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbdd9bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93010"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b661e41",
   "metadata": {},
   "source": [
    "### Make calls on a hopping window of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d46e6945",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping for few minutes, 299 calls made.\n",
      "Sleeping for few minutes, 598 calls made.\n",
      "Sleeping for few minutes, 897 calls made.\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "total_data = 0 \n",
    "collection = []\n",
    "callCount = 0\n",
    "\n",
    "while start < data.shape[0]:\n",
    "    end = start + 100\n",
    "    ids = ','.join(map(str,data.iloc[start:end]['author_id']))\n",
    "    collection.clear()\n",
    "    collection.extend(getUserData(ids)['data'])\n",
    "    start = end\n",
    "    \n",
    "    callCount += 1\n",
    "    \n",
    "    user_data = pd.DataFrame(collection)\n",
    "    name_file_csv = 'C:\\\\Users\\\\ayush\\\\OneDrive\\\\Desktop\\\\DataScience\\\\DataMining\\\\results\\\\users\\\\user' + str(callCount) + '.csv' \n",
    "    user_data.to_csv(name_file_csv, mode='w',index = False)\n",
    "    n = len(user_data)\n",
    "    total_data = total_data + n\n",
    "    user_data.drop(axis=0, labels = range(0,n), inplace=True)\n",
    "\n",
    "    if callCount % 299 == 0:\n",
    "        print(f\"Sleeping for few minutes, {callCount} calls made.\")\n",
    "        time.sleep(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc6d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('ConcatenatedUsers.csv')\n",
    "temp2 = pd.concat([temp,user_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3575b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2.drop_duplicates(['id']).to_csv('ConcatenatedUsers.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732900e1",
   "metadata": {},
   "source": [
    "### Get profile images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db541fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv('ConcatenatedUsers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e01692e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, user in user_data.iloc[:].iterrows():\n",
    "    url = str(user['profile_image_url'])\n",
    "    userid = str(user['id'])\n",
    "    \n",
    "    try:\n",
    "        img_data = requests.get(url).content\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    with open(f'C:\\\\Users\\\\ayush\\\\OneDrive\\\\Desktop\\\\DataScience\\\\DataMining\\\\results\\\\Images\\\\pf_{userid}.jpg', 'wb') as handler:\n",
    "        handler.write(img_data)\n",
    "    \n",
    "    calls += 1\n",
    "    if (calls % 100 == 0):\n",
    "        print(f'Calls made = {calls}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265a99f",
   "metadata": {},
   "source": [
    "### JSON Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d6d3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>created_at</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>name</th>\n",
       "      <th>protected</th>\n",
       "      <th>verified</th>\n",
       "      <th>url</th>\n",
       "      <th>username</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>entities</th>\n",
       "      <th>pinned_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(he/they) For those who need, we must do what ...</td>\n",
       "      <td>2014-09-20T18:53:50.000Z</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/145316546...</td>\n",
       "      <td>MintyFreshness</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Intensefreshnes</td>\n",
       "      <td>2822594617</td>\n",
       "      <td>The cum zone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>📍 Dallas, TX I show you where the adventure is...</td>\n",
       "      <td>2010-06-09T02:39:11.000Z</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/143451186...</td>\n",
       "      <td>Dallas Latina Foodie</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/IfrZpDpvPs</td>\n",
       "      <td>allycelebrates</td>\n",
       "      <td>153642560</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>{'url': {'urls': [{'start': 0, 'end': 23, 'url...</td>\n",
       "      <td>1.450854e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#FBR #FuckTrump #TaxTheRich #BlackLivesMatter ...</td>\n",
       "      <td>2015-09-04T16:18:33.000Z</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/137127092...</td>\n",
       "      <td>DMoney</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dmoney31267</td>\n",
       "      <td>3449791700</td>\n",
       "      <td>Colorado, USA</td>\n",
       "      <td>{'description': {'hashtags': [{'start': 0, 'en...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stock Investor / Anytime Fitness Member</td>\n",
       "      <td>2015-10-21T23:30:07.000Z</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/749396738...</td>\n",
       "      <td>Ray Blackwell</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RayBlackwell7</td>\n",
       "      <td>4012849515</td>\n",
       "      <td>Warren, PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>press secretary for all gay people. digital gr...</td>\n",
       "      <td>2019-05-31T19:15:03.000Z</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/144449859...</td>\n",
       "      <td>kaitlyn 🇬🇹</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/Y8aIhEM8jN</td>\n",
       "      <td>kaitlynsolares</td>\n",
       "      <td>1134538801680977920</td>\n",
       "      <td>Boston 🐀</td>\n",
       "      <td>{'url': {'urls': [{'start': 0, 'end': 23, 'url...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  (he/they) For those who need, we must do what ...   \n",
       "1  📍 Dallas, TX I show you where the adventure is...   \n",
       "2  #FBR #FuckTrump #TaxTheRich #BlackLivesMatter ...   \n",
       "3            Stock Investor / Anytime Fitness Member   \n",
       "4  press secretary for all gay people. digital gr...   \n",
       "\n",
       "                 created_at  \\\n",
       "0  2014-09-20T18:53:50.000Z   \n",
       "1  2010-06-09T02:39:11.000Z   \n",
       "2  2015-09-04T16:18:33.000Z   \n",
       "3  2015-10-21T23:30:07.000Z   \n",
       "4  2019-05-31T19:15:03.000Z   \n",
       "\n",
       "                                   profile_image_url                  name  \\\n",
       "0  https://pbs.twimg.com/profile_images/145316546...        MintyFreshness   \n",
       "1  https://pbs.twimg.com/profile_images/143451186...  Dallas Latina Foodie   \n",
       "2  https://pbs.twimg.com/profile_images/137127092...                DMoney   \n",
       "3  https://pbs.twimg.com/profile_images/749396738...         Ray Blackwell   \n",
       "4  https://pbs.twimg.com/profile_images/144449859...            kaitlyn 🇬🇹   \n",
       "\n",
       "   protected  verified                      url         username  \\\n",
       "0      False     False                      NaN  Intensefreshnes   \n",
       "1      False     False  https://t.co/IfrZpDpvPs   allycelebrates   \n",
       "2      False     False                      NaN      dmoney31267   \n",
       "3      False     False                      NaN    RayBlackwell7   \n",
       "4      False     False  https://t.co/Y8aIhEM8jN   kaitlynsolares   \n",
       "\n",
       "                    id       location  \\\n",
       "0           2822594617   The cum zone   \n",
       "1            153642560     Dallas, TX   \n",
       "2           3449791700  Colorado, USA   \n",
       "3           4012849515    Warren, PA    \n",
       "4  1134538801680977920       Boston 🐀   \n",
       "\n",
       "                                            entities  pinned_tweet_id  \n",
       "0                                                NaN              NaN  \n",
       "1  {'url': {'urls': [{'start': 0, 'end': 23, 'url...     1.450854e+18  \n",
       "2  {'description': {'hashtags': [{'start': 0, 'en...              NaN  \n",
       "3                                                NaN              NaN  \n",
       "4  {'url': {'urls': [{'start': 0, 'end': 23, 'url...              NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dicts = []\n",
    "\n",
    "for _, row in user_data.iterrows():\n",
    "    \n",
    "    # Preprocess description\n",
    "    description = str(row['description'])\n",
    "    description = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", description)\n",
    "    description = html.unescape(description)\n",
    "    description = re.sub('[^A-Za-z ]+', '', description)\n",
    "    description = description.strip().lower()\n",
    "    description = ' '.join(description.split())\n",
    "    \n",
    "    # Preprocess name\n",
    "    name = str(row['name'])\n",
    "    name = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", name)\n",
    "    name = html.unescape(name)\n",
    "    name = re.sub('[^A-Za-z ]+', '', name)\n",
    "    name = name.strip().lower()\n",
    "    name = ' '.join(name.split())\n",
    "    \n",
    "    # Preprocess username\n",
    "    username = str(row['username'])\n",
    "    username = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", username)\n",
    "    username = html.unescape(username)\n",
    "    username = re.sub('[^A-Za-z ]+', '', username)\n",
    "    username = username.strip().lower()\n",
    "    username = ' '.join(username.split())\n",
    "    \n",
    "    \n",
    "    if not os.path.isfile(f'new_profile_images/user_{row[\"id\"]}.jpg'):\n",
    "        img = '/content/profile_images/missing_image.jpg'\n",
    "    else:\n",
    "        img = f'/content/profile_images/user_{row[\"id\"]}.jpg'\n",
    "    \n",
    "    user_dict = {\n",
    "        \"id\": str(row['id']),\n",
    "        \"name\": name,\n",
    "        \"screen_name\": username,\n",
    "        \"description\": description,\n",
    "        \"lang\": \"en\",\n",
    "        \"img_path\":img\n",
    "    }\n",
    "    \n",
    "    json_dicts.append(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb505f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('data.jsonl', 'w') as writer:\n",
    "    writer.write_all(json_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e7673e",
   "metadata": {},
   "source": [
    "### Remove alpha channel from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0714ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasAlpha(image_path):\n",
    "    with wand.image.Image(filename=image_path) as img0:\n",
    "        alpha = img.alpha_channel\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cf660ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeAlpha(image_path, new_image_path):\n",
    "    with wand.image.Image(filename=image_path) as img:\n",
    "        img.alpha_channel = 'remove' \n",
    "        img.background_color = wand.image.Color('red')\n",
    "        img.save(filename=new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad049120",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in user_data.iterrows():\n",
    "    url = f'profile_images_orig/user_{row[\"id\"]}.jpg'\n",
    "    new_url = f'profile_images/user_{row[\"id\"]}.jpg'\n",
    "    if os.path.isfile(url):\n",
    "        try:\n",
    "            removeAlpha(url, new_url)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c514150",
   "metadata": {},
   "source": [
    "## image resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a692d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for _, row in user_data.iterrows():\n",
    "    new_url = f'C:/Users/ayush/OneDrive/Desktop/DataScience/DataMining/results/New_images/pf_{row[\"id\"]}.jpg'\n",
    "    if os.path.isfile(new_url): \n",
    "        img = cv.imread(new_url)\n",
    "        w,h,_ = img.shape\n",
    "        if w != 48 or h != 48:\n",
    "            arr.append(row['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d65bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "src_dir = \"C:\\\\Users\\\\ayush\\\\OneDrive\\\\Desktop\\\\DataScience\\\\DataMining\\\\EndProject\\\\Users\\\\profile_images2\"\n",
    "dst_dir = \"C:\\\\Users\\\\ayush\\\\OneDrive\\\\Desktop\\\\DataScience\\\\DataMining\\\\EndProject\\\\Users\\\\New Folder\"\n",
    "for jpgfile in glob.iglob(os.path.join(src_dir, \"*.jpg\")):\n",
    "    shutil.copy(jpgfile, dst_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9112344a",
   "metadata": {},
   "source": [
    "### Find grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a67401",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3154eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_graysc = []\n",
    "\n",
    "for _, row in user_data.iterrows():\n",
    "    new_url = f'C:/Users/ayush/OneDrive/Desktop/DataScience/DataMining/results/New_images/pf_{row[\"id\"]}.jpg'\n",
    "    if os.path.isfile(new_url):\n",
    "        img = cv.imread(new_url)\n",
    "        w,h,_ = img.shape\n",
    "        flag = True\n",
    "        for i in range(w):\n",
    "            \n",
    "            if not flag:\n",
    "                break\n",
    "            \n",
    "            for j in range(h):\n",
    "                r, g, b = img[i][j]\n",
    "                if r == g == b: \n",
    "                    pass\n",
    "                else:\n",
    "                    flag = False\n",
    "                    break\n",
    "        \n",
    "        if flag:\n",
    "#             print(row['id'])\n",
    "            collect_graysc.append(row[\"id\"])\n",
    "    \n",
    "len(collect_graysc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in collect_graysc:\n",
    "    user_data = user_data.drop(user_data[user_data.id == i].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ea70d",
   "metadata": {},
   "source": [
    "### M3 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f332198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install m3inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from m3inference import M3Inference\n",
    "import pprint\n",
    "m3=M3Inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae68e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = m3.infer('data.jsonl') \n",
    "pprint.pprint(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c084e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
